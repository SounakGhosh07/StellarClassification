{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "co5XVSTVGMfI"
      },
      "outputs": [],
      "source": [
        "#Importing necessary libraries\n",
        "import tensorflow as tf \n",
        "from tensorflow.keras.models import Model\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import tensorflow_hub as hub\n",
        "import os\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing import image\n",
        "from matplotlib.pyplot import imread\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import confusion_matrix, classification_report , accuracy_score\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbfqhSnZG-xQ",
        "outputId": "8c2af1d8-bda0-4190-a3dc-afda584ff89b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "#Mounting Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8noWkdkkG_r1",
        "outputId": "f3cd7871-3555-4a1e-a199-ac8694c098d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            id  ultraviolet_filter  green_filter  red_filter  \\\n",
            "0            1            17.44385      15.71196    16.14848   \n",
            "1            2            22.02806      24.01481    21.16334   \n",
            "2            3            23.07242      21.79252    20.51945   \n",
            "3            4            23.45985      23.41583    20.36645   \n",
            "4            5            23.89627      23.18005    21.12911   \n",
            "...        ...                 ...           ...         ...   \n",
            "134906  134907            19.24538      18.80673    16.41091   \n",
            "134907  134908            23.41124      22.59072    22.50731   \n",
            "134908  134909            21.76064      20.16531    20.07795   \n",
            "134909  134910            18.55473      17.70518    16.67601   \n",
            "134910  134911            22.07739      20.55631    20.97874   \n",
            "\n",
            "        near_infrared_filter       alpha      delta  redshift  stellar  \n",
            "0                  15.647619  158.167937  29.746275  0.094857        1  \n",
            "1                  20.214615  145.916931  38.083063  0.361631        1  \n",
            "2                  18.159421  245.684677  49.908866 -0.000065        2  \n",
            "3                  20.220636  204.812750  33.137303  0.643375        1  \n",
            "4                  19.818470  209.254795  55.296589  0.486448        1  \n",
            "...                      ...         ...        ...       ...      ...  \n",
            "134906             15.609013    6.218972  19.934894  0.049424        1  \n",
            "134907             22.023594  152.664791  46.368871  0.610840        3  \n",
            "134908             20.315816  358.506516  42.845364  2.133721        3  \n",
            "134909             15.922038  160.649389  18.329627  0.052593        1  \n",
            "134910             20.568744    9.907348  -1.612387 -0.000084        2  \n",
            "\n",
            "[134911 rows x 9 columns]\n"
          ]
        }
      ],
      "source": [
        "#Loading the train dataset\n",
        "df_train = pd.read_csv('/content/gdrive/MyDrive/train_NoNTTqq.csv')\n",
        "print(df_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FuBnWuYoInxu"
      },
      "outputs": [],
      "source": [
        "#Dropping the id column from the train dataframe\n",
        "df_train.drop(columns='id', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "jUVJasSFQVxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cf = np.array([[167, 4, 0, 0, 0],\n",
        "               [2, 144, 4, 1, 5],\n",
        "               [0, 1, 160, 0, 0],\n",
        "               [0, 1, 1, 146, 0],\n",
        "               [0, 1, 3, 0, 170]])"
      ],
      "metadata": {
        "id": "vLeRFVexP4aL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "sns.heatmap(cf, annot = True,fmt ='.4g', cmap ='Blues')"
      ],
      "metadata": {
        "id": "BO7I6JFwQYvI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_TqiVv6HmDSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SjxkoMktVidt"
      },
      "outputs": [],
      "source": [
        "#Replacing each value of stellar column to be in line with SparseCategoricalCrossentropy\n",
        "df_train['stellar'].replace({\n",
        "    1:0,\n",
        "    2:1,\n",
        "    3:2\n",
        "}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Pqh3O2VHgRz"
      },
      "outputs": [],
      "source": [
        "#Loading the test dataset\n",
        "df_test = pd.read_csv('/content/gdrive/MyDrive/test_SxgqOdc.csv')\n",
        "df_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FsQUviYvJ8jw"
      },
      "outputs": [],
      "source": [
        "#Storing the columns of train dataframe other than stellar in X and storing the stellar column of train dataframe in Y\n",
        "X = df_train.drop('stellar', axis='columns')\n",
        "Y = df_train.stellar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqWsm3lAK7JK"
      },
      "outputs": [],
      "source": [
        "#Train test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_val, y_train, y_val = train_test_split(X,Y,test_size=0.00001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mr6eNluvM_Ll"
      },
      "outputs": [],
      "source": [
        "#Dropping the id colum of test dataframe\n",
        "df_test_p = df_test.drop('id', axis='columns')\n",
        "df_test_p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CpiBdWsIuuAg"
      },
      "outputs": [],
      "source": [
        "#Standard Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "st_x= StandardScaler()\n",
        "x_train_scaled= st_x.fit_transform(x_train)\n",
        "x_test_scaled= st_x.transform(df_test_p)\n",
        "x_val_scaled = st_x.transform(x_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YVMShYcTuYly"
      },
      "outputs": [],
      "source": [
        "#RandomForest Classifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "model1 = RandomForestClassifier(n_estimators=150)\n",
        "model1.fit(x_train_scaled, y_train) \n",
        "model1.score(x_val_scaled, y_val) "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Storing the predicted probabilities obtained using RandomForest Classifier for test data\n",
        "pred_prob_test_rf = np.array(model1.predict_proba(x_test_scaled))\n",
        "print(pred_prob_test_rf)"
      ],
      "metadata": {
        "id": "-D5zqcbt_c_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Adaboost Classifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "adaboost = AdaBoostClassifier(n_estimators=150, base_estimator= None,learning_rate=0.1, random_state = 1)\n",
        "adaboost.fit(x_train_scaled,y_train)\n",
        "\n",
        "print(adaboost.score(x_val_scaled, y_val))"
      ],
      "metadata": {
        "id": "9IymHigeACLp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Storing the predicted probabilities obtained using Adaboost Classifier for test data\n",
        "pred_prob_test_ada = np.array(adaboost.predict_proba(x_test_scaled))\n",
        "print(pred_prob_test_ada)"
      ],
      "metadata": {
        "id": "KkWyFmpZAdV_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#LGBM Classifier\n",
        "import lightgbm as ltb\n",
        "model2 = ltb.LGBMClassifier(learning_rate=0.09,max_depth=-5,random_state=42)\n",
        "model2.fit(x_train_scaled,y_train)\n",
        "model2.score(x_val_scaled, y_val)"
      ],
      "metadata": {
        "id": "Sx1HwXBvHl_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Storing the predicted probabilities obtained using LGBM Classifier for test data\n",
        "pred_prob_test_lgbm = np.array(model2.predict_proba(x_test_scaled))\n",
        "print(pred_prob_test_lgbm)"
      ],
      "metadata": {
        "id": "UO-yWDYJDTqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Installing the catboost library\n",
        "!pip install catboost"
      ],
      "metadata": {
        "id": "-RUmSMAzExbs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CatBoost Classifier\n",
        "import catboost as cb\n",
        "model3 = cb.CatBoostClassifier()\n",
        "model3.fit(x_train_scaled,y_train)\n",
        "model3.score(x_val_scaled, y_val)"
      ],
      "metadata": {
        "id": "P2v_1aI8Ehlx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Storing the predicted probabilities obtained using CatBoost Classifier for test data\n",
        "pred_prob_test_cat = np.array(model3.predict_proba(x_test_scaled))\n",
        "print(pred_prob_test_cat)"
      ],
      "metadata": {
        "id": "TM_djQsNFPRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#GradientBoosting Classifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "gb_clf = GradientBoostingClassifier(n_estimators=100, max_features=2, max_depth=2, random_state=0)\n",
        "gb_clf.fit(x_train_scaled,y_train)\n",
        "gb_clf.score(x_val_scaled, y_val)"
      ],
      "metadata": {
        "id": "f_xxK-_jYhgh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Storing the predicted probabilities obtained using GradientBoosting Classifier for test data\n",
        "pred_prob_test_gb = np.array(gb_clf.predict_proba(x_test_scaled))\n",
        "print(pred_prob_test_gb)"
      ],
      "metadata": {
        "id": "LPc6n72JZQMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ExtraTrees Classifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "etf = ExtraTreesClassifier(n_estimators = 100,criterion ='entropy')\n",
        "etf.fit(x_train_scaled,y_train)\n",
        "etf.score(x_val_scaled, y_val)"
      ],
      "metadata": {
        "id": "RE71pozhF0aS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Storing the predicted probabilities obtained using ExtraTrees Classifier for test data\n",
        "pred_prob_test_etf = np.array(etf.predict_proba(x_test_scaled))\n",
        "print(pred_prob_test_etf)"
      ],
      "metadata": {
        "id": "TNE-5iMMGM_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs_per_model = 40\n",
        "lr_max = 0.001"
      ],
      "metadata": {
        "id": "rhvQ4b8FCTJm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Learning Rate Scheduling for ANN\n",
        "import math\n",
        "def cosine_annealing(epoch):\n",
        "        cos_inner = (math.pi * (epoch % n_epochs_per_model)) / n_epochs_per_model\n",
        "        return lr_max / 2 * (math.cos(cos_inner) + 1)"
      ],
      "metadata": {
        "id": "xFVrgjdkCFVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L16zHUiXamUJ"
      },
      "outputs": [],
      "source": [
        "callback = tf.keras.callbacks.LearningRateScheduler(cosine_annealing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dDUg3tkkTqFw"
      },
      "outputs": [],
      "source": [
        "#ANN\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "\n",
        "model_ann = keras.Sequential([\n",
        "    keras.layers.Dense(7, input_shape=(7,), activation='relu'),\n",
        "    keras.layers.Dense(15, activation='relu'),\n",
        "    keras.layers.Dense(80, activation='relu'), \n",
        "    keras.layers.Dense(200, activation='relu'),\n",
        "    keras.layers.Dropout(0.3),\n",
        "    keras.layers.Dense(100, activation='relu'),\n",
        "    keras.layers.Dropout(0.3),\n",
        "    keras.layers.Dense(40, activation='relu'),\n",
        "    keras.layers.Dense(20, activation='relu'),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "model_ann.compile(optimizer='adam',\n",
        "              loss='SparseCategoricalCrossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_ann.fit(x_train_scaled, y_train, callbacks = [callback],validation_data=(x_val_scaled, y_val), epochs= 40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fItC_idrdAdG",
        "outputId": "ccd623d9-5667-4f54-d565-a5afb290c157"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2811/2811 [==============================] - 5s 2ms/step\n",
            "[[6.2942110e-02 9.3620700e-01 8.5094135e-04]\n",
            " [9.8847586e-01 1.0635775e-02 8.8825234e-04]\n",
            " [3.1274137e-01 7.7202404e-03 6.7953837e-01]\n",
            " ...\n",
            " [9.5337498e-01 4.2527270e-02 4.0977774e-03]\n",
            " [2.1943133e-02 9.7703892e-01 1.0179415e-03]\n",
            " [9.8134065e-01 1.0600814e-02 8.0584576e-03]]\n"
          ]
        }
      ],
      "source": [
        "#Storing the predicted probabilities obtained using ANN for test data\n",
        "pred_prob_test_ann = model_ann.predict(x_test_scaled)\n",
        "print(pred_prob_test_ann)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Ensembling with experimental weights\n",
        "pred_ensem_test_final = (4*pred_prob_test_lgbm + 3*pred_prob_test_rf + 20*pred_prob_test_cat + 2*pred_prob_test_etf + 5*pred_prob_test_gb + pred_prob_test_ada+3*pred_prob_test_ann)/38\n",
        "print(pred_ensem_test_final)"
      ],
      "metadata": {
        "id": "hswWxYkwET5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "229a4260-3cc4-4d81-da07-931a60a36314"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.11225686 0.87762035 0.0101228 ]\n",
            " [0.97486372 0.01585527 0.009281  ]\n",
            " [0.25204526 0.02591409 0.72204065]\n",
            " ...\n",
            " [0.94942116 0.03146894 0.01910991]\n",
            " [0.01485498 0.97635912 0.00878591]\n",
            " [0.9729171  0.01203826 0.01504464]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_ensem_test = []\n",
        "for i in pred_ensem_test_final:\n",
        "  pred_ensem_test.append(np.argmax(i)+1)\n",
        "pred_ensem_test = np.array(pred_ensem_test)\n",
        "print(pred_ensem_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "siDyhfJEJq6t",
        "outputId": "a70115b5-2b2a-4725-e3a5-86baabd1fe4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2 1 3 ... 1 2 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jm_RfZDfKETw"
      },
      "outputs": [],
      "source": [
        "#Converting to dataframe\n",
        "dfx = pd.DataFrame(list(zip(pred_ensem_test)),\n",
        "               columns = ['stellar'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DZA9CtwEKETx"
      },
      "outputs": [],
      "source": [
        "dfx.to_csv('SOS_ensemble_final.csv')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}